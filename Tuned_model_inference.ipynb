{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0a2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers trl accelerate torch bitsandbytes peft sentencepiece wandb datasets -qU \n",
    "!pip install huggingface-hub -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b6d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14da5167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71021134dec49c6af77839f33dad9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c38c0b822c4b5aadaf69948db62512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c52236720e7485d990a20c95376872c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0e7ef0e495422ca0eab0982ac9a149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76c83819f6b47ed8f7d7151ab450c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ed3d4045c9488d9b95804d4428815f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2f06b3d93149058a631d25a10e2b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02efe6c84074fa6a8984bf89c361d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device_map='auto',\n",
    "    quantization_config=nf4_config,\n",
    "    use_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f010508d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af00d8ee9dde40f2afa10d88d356c3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/652 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288ce983c07e43548a678820929dd544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87e2fff931644d4a7e7b0da691584c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c85a7467b8d42838c83fef97aeaf8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4324e687f24ea68d88736c74352129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888b7279d35142448ee60fcf4901ae4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db62d0a214f4b709200fe855dea44a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644e44616144436db9d32d340e2c1ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"gouthamsk/mistral-embedded-c-v0.3\",\n",
    "    device_map='auto',\n",
    "    quantization_config=nf4_config,\n",
    "    use_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af24ffe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610119bf32b54a3dba71ef897134f597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8f7ffec22d482188bc6bb933c1ed28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1bc7c702fd418fad9c44ab574cdb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d935fafa1824646a31aa2b4a24eb523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e018b6243d4c6190d3502589080789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65de16e1e5c746909cdd45ca12c6caed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f48359b4f6641f4a380c7ac00384217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e977d34517b1414eb2d482cc3522eeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a203a6faf379460b8551db6e75523764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b528e92a4d2041489312a3a0af319ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b005ff76cb0143ef9842fea6afc4ef6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50abbf6fb09e4cfca4da6df74c9c5035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"gouthamsk/mistral-embedded-c-instruct-v0.4\",\n",
    "    device_map='auto',\n",
    "    quantization_config=nf4_config,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gouthamsk/mistral-embedded-c-instruct-v0.4\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e96354f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1e5ab7c8544c06a3133b07fad11682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/630 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb2e4fc729f4059b8f8c5a119e4c716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/109M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "config = PeftConfig.from_pretrained(\"gouthamsk/mistral_embedded_c\")\n",
    "tuned_model = PeftModel.from_pretrained(model, \"gouthamsk/mistral_embedded_c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eeb58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169fb088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr  9 08:44:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   47C    P0              27W /  70W |  13883MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     11557      C   /opt/conda/bin/python                     13878MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab13e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(r'/Users/biboxdev/Desktop/research/codeBert/fine_tuning/embededd_new.csv')\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "dataset.push_to_hub(\"gouthamsk/embedded_dataset_mixed_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529df2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec4ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model):\n",
    "  encoded_input = tokenizer(prompt,  return_tensors=\"pt\", add_special_tokens=True)\n",
    "  model_inputs = encoded_input.to('cuda')\n",
    "\n",
    "  generated_ids = model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "  decoded_output = tokenizer.batch_decode(generated_ids)\n",
    "  return decoded_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47915b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> write a program to blink a led for ESP32 with  1 second delay\\n\\n#include <stdio.h>\\n#include \"freertos/FreeRTOS.h\"\\n#include \"freertos/task.h\"\\n#include <driver/gpio.h>\\n#define LED_PIN GPIO_NUM_2 // Define the GPIO pin to which the LED is connected\\nvoid app_main() {\\n    // Configure the GPIO pin as output\\n    esp_err_t result = gpio_config(LED_PIN, &gpio_config_t{\\n        .pin_bit_mask = (1ULL << LED_PIN),\\n        .mode = GPIO_MODE_OUTPUT,\\n    });\\n    if (result != ESP_OK) {\\n        printf(\"GPIO configuration failed with error: %s\\\\n\",\\n                esp_err_to_name(result));\\n        exit(1);\\n    }\\n    while (1) {\\n        // Turn the LED on\\n        gpio_set_level(LED_PIN, 1);\\n        // Wait for 1 second\\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\\n        // Turn the LED off\\n        gpio_set_level(LED_PIN, 0);\\n        // Wait for 1 second\\n        vTaskDelay(1000 / portTICK_PERIOD_MS);\\n    }\\n}</s>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"write a program to blink a led for ESP32\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d884c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> write a program to blink a led for ESP32 using the Arduino IDE\\n\\nTo blink an LED on an ESP32 using the Arduino IDE, follow these steps:\\n\\n1. Set up the ESP32 development environment:\\n   Install the Arduino IDE, then add the BoardManager.json and ESP32 board files from the official ESP32 repository: https://github.com/espressif/arduino-esp32\\n\\n2. Create a new Arduino sketch:\\n   In Arduino IDE, create a new sketch by clicking \"File\" -> \"New\" or by using the keyboard shortcut \"Ctrl+N\".\\n\\n3. Connect the LED and resistor:\\n   Connect the LED to an digital I/O pin on the ESP32 using a 220Ω resistor.\\n\\n4. Write the Arduino code:\\n   In your new sketch, paste the following code:\\n\\n```C++\\n#define LED_PIN 2\\n\\nvoid setup() {\\n  pinMode(LED_PIN, OUTPUT); // configure LED_PIN as an output\\n}\\n\\nvoid loop() {\\n  digitalWrite(LED_PIN, HIGH); // turn the LED on (HIGH is the voltage level)\\n  delay(1000); // wait for a second\\n  digitalWrite(LED_PIN, LOW);  // turn the LED off by making the voltage LOW\\n  delay(1000); // wait for a second\\n}\\n```\\n\\nReplace `LED_PIN` with the number of the pin connected to the LED.\\n\\n5. Upload the code:\\n   Click \"Tools\" -> \"Board\" and select the corresponding ESP32 board for your development board. Then click \"Tools\" -> \"Port\" to choose the USB port connected to your ESP32. Finally, click the \"Upload\" button to compile and upload the code to the ESP32.\\n\\n6. Verify the LED blink:\\n   The LED should now be blinking at a 1 second on-off interval.</s>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"write a program to blink a led for ESP32\",base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e91e9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ESP HTTP Client Overview esp_http_client component provides a set of APIs to easily send, post and upload data to various HTTP and WebSocket servers. It uses the FreeRTOS+ TCP transport layer and is designed for both HTTP and WebSocket connections. This component is lightweight and minimalistic, using only required features with efficient memory usage. The APIs are designed for both synchronous and asynchronous use cases, which allows the user to choose the best solution for a particular use case. Key features: * Uses FreeRTOS+TCP transport layer for reliable connection and event handling * Supports both HTTP and HTTPS protocols * Supports both binary and text response handling * Supports asynchronous and synchronous requests * Supports multiple ongoing transfers * Supports HTTP and HTTPS Keep-Alive * Supports automatic redirection following 3xx status codes * Supports streaming data over HTTP, using the chunked transfer encoding * Supports reading and writing Cookies* Supports basic and digest authentication\\n\\nUsing ESP HTTP Client To send HTTP requests using esp_http_client, you need to initialize the component, create a handle for a new client, configure the request, and then send the request. Here\\'s a high-level overview of the steps to do this:\\n\\n1. Initialize the ESP_HTTPS component\\nFirst, you need to initialize the ESP_HTTPS component before using it. This is typically done in your main function:\\n\\n```cpp\\n#include \"esp_log.h\"\\n#include \"esp_http_client.h\"\\n\\nvoid app_init() {\\n    esp_log_init(\"HTTP_example\", ESP_LOG_INFO);\\n    esp_netif_init();\\n    esp_event_loop_init(sys_event_t, esp_netif_event_Handler, NULL);\\n    wifi_init_station();\\n    init_OTA();\\n}\\n```\\n\\n2. Create a new client handle\\nNow create a handle for a new client using `http_client_new()` function.\\n\\n```cpp\\nhttp_handle_t *client = http_client_new();\\n```\\n\\n3. Configure the request\\nNext, configure the request using the set methods. For example, to set the method (GET), destination URL, and headers, you can do:\\n\\n```cpp\\nhttp_status_t status = HTTP_OK;\\nconst esp_char *host = \"example.com\";\\nconst esp_char *path = \"/path/to/resource\";\\nconst esp_char *query = \"param1=value1&param2=value2\";\\n\\nhttp_uri_t uri = { .host = host, .path = path, .query = query };\\n\\nstatus = http_client_set_method(client, HTTP_METHOD_GET);\\nstatus = status ? http_client_set_uri(client, &uri) : status;\\nstatus = status ? http_client_set_header(client, \"Authorization\", \"Bearer <token>\") : status;\\n```\\n\\n4. Send the request\\nAfter configuring the request, send the request using the `http_client_set_handle()` or `http_client_disconnect()` method, which depends on your use case.\\n\\nFor synchronous requests:\\n\\n```cpp\\nesp_err_t err = esp_err_make(ESP_ERROR_DNS_LOOKUP, ESP_FAILURE, \"Unknown DNS error\");\\nhttp_status_t response_status_code = HTTP_STATUS_CODE_INTERNAL_SERVER_ERROR;\\nstruct stat response_stat;\\nsize_t response_len = 0;\\nconst size_t buffer_size = 1024;\\nesp_char* response_buf = (esp_char*) malloc(buffer_size);\\nsize_t received = 0;\\n\\nstatus = status ? http_client_set_handle(client, &handle) : status;\\nerr = http_client_call(client, &handle, &response_status_code, &response_stat, &response_len, response_buf, buffer_size);\\n\\nfree(response_buf);\\n\\nESP_LOGI(\"ESP_HTTP_Client\", \"Response status code: %d\", response_status_code);\\nESP_LOGI(\"ESP_HTTP_Client\", \"Bytes received: %u\", received);\\nhttp_client_disconnect(client);\\n```\\n\\nFor asynchronous requests:\\n\\n```cpp\\nesp_err_t err = ESP_OK;\\nhttp_event_handle'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"how many interrupt do ESP32 have\",base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9001f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Delete a peer from peer list. - Parameters peer_addr -- peer MAC address 0x00:00:00:00:00:00 peer_index -- the peer index in peer list 0,1,2 ... peer_num -1: delete a peer from peer list successfully, else fail.  Return values: -ESP_OK succeed -1: delete a peer from peer list failed because no such peer in list ESP_ERR_INVALID_ARG : invalid argument ESP_ERR_NOT_FOUND : not found the peer in list ESP_ERR_ invalid : invalid argument ESP_ERR_NO_MEM : no memory to allocate ESP_ERR_TIMEOUT : timeout to delete a peer from peer list\\n-\\n-\\nesp_ble_mesh_add_static_mesh_addr(peer_addr, static_mesh_addr, static_mesh_addr_length, callback, user_ctx)\\nAdd permanent mesh address to a peer.\\n</s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"Delete a peer from peer list. - Parameters peer_addr -- peer MAC address \",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97648853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><s> The Light LC (Lightness Control) Server model extends the Light Lightness Server model and the Generic Server model. In this model, a server device with a light sensor can control the light level of a target device over Bluetooth Low Energy (BLE).\\n\\n# Architecture Overview\\nThe following figure shows an architecture of the Light LC Server model.\\n The application code contains the following components:\\n- Bluetooth Lightness Service (BLS) – defines service/characteristic UUIDs, and provides access to the service/characteristic data by an application framework.\\n- Attributes and Descriptors – the Light LC model uses various characteristics and descriptors.\\n- Application Framework – provides a user interface to interact with the BLS instance.\\n  Other architecture components that are not part of an application code are as follows:\\n- Bluetooth LE API (bluetooth/bluetooth-le) – contains an API for BLE specific features.\\n- Platform Abstraction Layer (PAL) (bluetooth/bluetooth-le/common) provides an API for stack features.\\n- Bluetooth Lightness Controller (BLC) – implements BLC functionality such as light level adjustment and lightness calculation.\\n- Bluetooth Lightness Light Level (BLLL) Server – is the BLE server with the BLS and the BLC functionalities.\\n- BLE stack – includes Bluetooth LE Controller (BLC) and Bluetooth LE Host (BLH) components.</s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"The Light LC (Lightness Control) Server model extends the Light Lightness Server model and the Generic\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0662e02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ESP-MQTT Overview ESP-MQTT is an implementation of MQTT protocol client, which is a lightweight, publish/subscribe messaging protocol that allows you to exchange data between devices using asynchronous methods. In this tutorial, you will learn how to create a simple web application to control an Espressif ESP8266 microcontroller using MQTT publish/subscribe messages. Prerequisites Before following this tutorial, make sure that you have the following:\\n\\n* A computer with a stable internet connection\\n* Latest Arduino IDE with ESP8266 board support package installed\\n* Basic understanding of MQTT protocol, C programming, and HTML/JavaScript\\n\\nHardware Requirements\\n\\n* ESP8266 board (e.g., NodeMCU, Wemos D1 Mini)\\n* A breadboard, wires, and some LEDs (optional)\\n\\nStep 1: Set Up the ESP8266 Board\\nCreate a new Arduino project and select the appropriate board. In this example, we will use the following board configuration:\\n\\n* Board: NodeMCU 1.0 (ESP-12)\\n* processor: ESP8266 with WiFi\\n* Flash size: 520 KB (or higher)\\n\\nStep 2: Write the ESP8266 Code to Publish and Subscribe to MQTT Topics\\nTo write the code, we will use the PubSubClient library, which supports the MQTT protocol. Make sure that you have downloaded and installed the library in your Arduino IDE.\\n\\nCreate a file in the project folder called `mqtt_client.ino` and paste the following code:\\n\\n```ard\\n#include <ESP8266WiFi.h>\\n#include <PubSubClient.h>\\n\\nconst char* ssid = \"your_SSID\";\\nconst char* password = \"your_PASSWORD\";\\nconst char* mqtt_server = \"your_MQTT_BROKER_URL\";\\nconst int mqtt_port = 1883;\\nconst char* client_name = \"ESP8266_MQTT_Client\";\\n\\nWiFiClient espClient;\\nPubSubClient client(espClient);\\n\\nvoid setup() {\\n  // Initialize serial communication and wait for the serial monitor to connect.\\n  Serial.begin(115200);\\n\\n  // Initialize WiFi connection.\\n  WiFi.begin(ssid, password);\\n\\n  // Wait for the connection to complete.\\n  delay(10);\\n\\n  if (WiFi.status() != W_STA_CONNECTED) {\\n    Serial.println(\"Unable to connect to WiFi\");\\n    // If the module fails to connect to the WiFi network, stop the code and display an error message.\\n    ESP.restart();\\n  }\\n\\n  // Initialize MQTT client and connect to the broker.\\n  client.setServer(mqtt_server, mqtt_port);\\n  client.setCallback(onMqttMessage);\\n}\\n\\nvoid loop() {\\n  // Attempt to reconnect to the MQTT broker if connection lost.\\n  if (!client.connected()) {\\n    reconnect();\\n  }\\n\\n  // Process any incoming MQTT messages.\\n  client.handleAvailableData();\\n\\n  // Publish a message every 1 second, if the connection to the MQTT broker is established.\\n  if (client.connected()) {\\n    publishMessage();\\n    delay(1000);\\n  }\\n}\\n\\nvoid reconnect() {\\n  // Attempt to connect to the MQTT broker using a callback function.\\n  if (client.connect(client_name)) {\\n    // When the connection is established, subscribe to the test topic.\\n    client.subscribe(\"test/topic_subscribe\");\\n  } else {\\n    // If the connection fails, wait and try again.\\n    Serial.println(\"Failed to connect to MQTT broker. Retry in 5 seconds...\");\\n    delay(5000);\\n  }\\n}\\n\\nvoid publishMessage() {\\n  // Publish a message to the test topic.\\n  String message = \"Hello from ESP8266!\";\\n  Serial.println(\"Publishing message to test/topic: \" + message);\\n  client.publish(\"test/topic_publish\", message.c_str());\\n}\\n\\nvoid onMqttMessage(const char* topic, byte* msg, int len)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"ESP-MQTT Overview ESP-MQTT is an implementation of MQTT protocol client, which is a\",base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f978c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Delete a peer from peer list. - Parameters peer_addr -- peer MAC address --------------------------- - code block-------------------------- ```lua function delete_peer(peer_addr) -- check if peer is in the peer list if not, error return _,_,_, peer in peer_list then -- remove peer from the table peer_list[peer_addr] = nil end end ``` Note: This code snippet assumes that `peer_list` is a table that maps peer MAC addresses to their network interfaces. You may need to modify the function `delete_peer` according to your implementation.</s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"Delete a peer from peer list. - Parameters peer_addr -- peer MAC address \",base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6392df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/biboxdev/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "df_mixed = pd.read_csv(r'/Users/biboxdev/Desktop/research/codeBert/fine_tuning/dataset_new - train.csv')\n",
    "df = pd.read_csv(r'/Users/biboxdev/Desktop/research/codeBert/fine_tuning/mistal_training/c_dataset.csv')\n",
    "df.drop(columns=['lang','resource'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a1472a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a C program to print the elements of a t...</td>\n",
       "      <td>Here is a C program that prints the elements o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a C program that prompts the user to ent...</td>\n",
       "      <td>Here is an example C program that prompts the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please generate a system variable in C languag...</td>\n",
       "      <td>Implementing a complete date and time system t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Write a C program to calculate the order of a ...</td>\n",
       "      <td>Here's a C program that meets the requirements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Build a program in C to find all prime numbers...</td>\n",
       "      <td>Here is an implementation of the program in C:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Write a function in C that swaps the first and...</td>\n",
       "      <td>Here is the code for the function in C that sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Convert the given linear equation ax + b = c i...</td>\n",
       "      <td>It is not possible to convert the given linear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Re-write the code in the given input to calcul...</td>\n",
       "      <td>def fibonacci(n):\\n    if n &lt;= 1:\\n        ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Create a function in C that takes a string as ...</td>\n",
       "      <td>Here is a possible implementation of the funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Design a C code to accept an array of integers...</td>\n",
       "      <td>Here is a C code that accepts an array of inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 query  \\\n",
       "0    Write a C program to print the elements of a t...   \n",
       "1    Write a C program that prompts the user to ent...   \n",
       "2    Please generate a system variable in C languag...   \n",
       "3    Write a C program to calculate the order of a ...   \n",
       "4    Build a program in C to find all prime numbers...   \n",
       "..                                                 ...   \n",
       "145  Write a function in C that swaps the first and...   \n",
       "146  Convert the given linear equation ax + b = c i...   \n",
       "147  Re-write the code in the given input to calcul...   \n",
       "148  Create a function in C that takes a string as ...   \n",
       "149  Design a C code to accept an array of integers...   \n",
       "\n",
       "                                                answer  \n",
       "0    Here is a C program that prints the elements o...  \n",
       "1    Here is an example C program that prompts the ...  \n",
       "2    Implementing a complete date and time system t...  \n",
       "3    Here's a C program that meets the requirements...  \n",
       "4    Here is an implementation of the program in C:...  \n",
       "..                                                 ...  \n",
       "145  Here is the code for the function in C that sw...  \n",
       "146  It is not possible to convert the given linear...  \n",
       "147  def fibonacci(n):\\n    if n <= 1:\\n        ret...  \n",
       "148  Here is a possible implementation of the funct...  \n",
       "149  Here is a C code that accepts an array of inte...  \n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:150]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f31c9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 34.63ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/gouthamsk/embedded_dataset_mixed_small/commit/53a4f199d00546ef2a0a22809aaab24cbd76145e', commit_message='Upload dataset', commit_description='', oid='53a4f199d00546ef2a0a22809aaab24cbd76145e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.rename(columns={'query': 'instruction'}, inplace=True)\n",
    "df.rename(columns={'answer': 'output'}, inplace=True)\n",
    "result = pd.concat([df, df_mixed])\n",
    "# df.head()\n",
    "result = result.reset_index(drop=True)\n",
    "result\n",
    "dataset = Dataset.from_pandas(result)\n",
    "dataset_shuffled = dataset.shuffle(seed=42)\n",
    "dataset_shuffled\n",
    "dataset_shuffled.push_to_hub(\"gouthamsk/embedded_dataset_mixed_small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5acda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae756ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.49.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.1/159.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/biboxdev/miniconda3/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/biboxdev/miniconda3/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/biboxdev/miniconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/biboxdev/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.3-cp311-cp311-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.49.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3 pillow-10.2.0 pyparsing-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bf04e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "def create_text_row(data):\n",
    "    if(input==None):\n",
    "        text_row = f\"\"\"<s>[INST]{data['instruction']}[/INST]\\\\n{data['output']}</s>\"\"\"\n",
    "    else :\n",
    "        text_row = f\"\"\"<s>[INST]{data['instruction']} with {data['input']} [/INST] \\n {data['output']}</s>\"\"\"\n",
    "    return text_row\n",
    "\n",
    "def prepare_train_data(data_id):\n",
    "    data = load_dataset(data_id, split=\"train\")\n",
    "    data_df = data.to_pandas() \n",
    "    data_df[\"text\"] =data_df.apply(create_text_row, axis =1) \n",
    "    data = Dataset.from_pandas(data_df)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7fe9ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 350/350 [00:00<00:00, 1.73MB/s]\n",
      "Downloading data: 100%|██████████| 292k/292k [00:00<00:00, 341kB/s]\n",
      "Generating train split: 100%|██████████| 452/452 [00:00<00:00, 11122.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "instruct_tune_dataset = prepare_train_data(\"gouthamsk/embedded_dataset_mixed_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7042a19",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m df\u001b[39m=\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[39m# Calculate token length\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtoken_length\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39msplit()))\n\u001b[1;32m     12\u001b[0m \u001b[39m# Plotting\u001b[39;00m\n\u001b[1;32m     13\u001b[0m plt\u001b[39m.\u001b[39mhist(df[\u001b[39m'\u001b[39m\u001b[39mtoken_length\u001b[39m\u001b[39m'\u001b[39m], bins\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mmax\u001b[39m(df[\u001b[39m'\u001b[39m\u001b[39mtoken_length\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m), edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1111\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1114\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1227\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1228\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1230\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1231\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame\n",
    "# data = {'text': ['Hello world', 'This is a test']}\n",
    "df = pd.DataFrame(instruct_tune_dataset)\n",
    "\n",
    "# Calculate token length\n",
    "df['token_length'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.hist(df['token_length'], bins=range(1, max(df['token_length']) + 2), edgecolor='black')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Token Length Distribution')\n",
    "plt.xticks(range(1, max(df['token_length']) + 1))\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744658c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "  output_dir = \"mistral_embedded_c_v0.2\",\n",
    "  #num_train_epochs=10,\n",
    "  max_steps = 300, # comment out this line if you want to train in epochs\n",
    "  per_device_train_batch_size = 4,\n",
    "  warmup_steps = 0.03,\n",
    "  logging_steps=10,\n",
    "  save_strategy=\"epoch\",\n",
    "  #evaluation_strategy=\"epoch\",\n",
    "  # evaluation_strategy=\"steps\",\n",
    "  # eval_steps=20, # comment out this line if you want to evaluate at the end of each epoch\n",
    "  learning_rate=2e-4,\n",
    "  bf16=True,\n",
    "  lr_scheduler_type='constant',\n",
    "  report_to=\"wandb\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
